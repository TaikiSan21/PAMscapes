# Day 1

## Intro

Do we need to read some MANTA metadata from NetCDF? Not sure if needed
for PAMscapes plots...

Probably need to read data quality flag from MANTA netcdf to mark out
unuseable/bad sections. Maybe `loadMantaNc` needs to print
comment if any are found

Double check pypam compatiblity

```{r}
# check manta nc
library(ncdf4)
library(here)
ncFile <- here('testData/nrs_products_sound_level_metrics_11_nrs_11_20191023-20211004_hmd_data_NRS11_H5R6.1.5000_20191024_DAILY_MILLIDEC_MinRes.nc')
nc <- nc_open(ncFile)
```

Checking for data quality comments (`varid=0` gets global atts) and
reading qual flag matrix (1 = Good, 2 = Not evaluated/Unknown, 3 =  Compromised/Questionable , 4 = Unusable / Bad)

```{r}
ncatt_get(nc, 'comment', varid=0)
dataQual <- ncvar_get(nc, 'quality_flag', start=c(1,1), count=c(-1, -1))
dataQual <- t(dataQual)
dqLevels <- c('Good', 'Not evaluated/Unknown', 'Compromised/Questionable', 'Unusable/Bad')
dqHas <- unique(as.vector(dataQual))
dqLevels[dqHas]
```

 Testing using data quality flags to remove selected sections of data (user selects
 which ones they want to keep)
 
```{r}
library(patchwork)
manta <- loadMantaNc(ncFile)
mantaDq <- manta
keepQuals <- c(1)
dropIx <- matrix(!dataQual %in% keepQuals, nrow=nrow(dataQual))
mantaDq[2:ncol(mantaDq)][dropIx] <- NA
plotPSD(manta, style='density') /
    plotPSD(mantaDq, style='density')


```

Manta NC also stores image file? lets see..

```{r}
mantaPng <- ncvar_get(nc, 'psd_image', start=c(1,1), count=c(-1, -1))
pngColors <- ncvar_get(nc, 'psd_image_colormap', start=c(1,1), count=c(-1,-1))
image(t(mantaPng)[, nrow(mantaPng):1])
mantaPct <- ncvar_get(nc, 'percentile_image', start=c(1,1), count=c(-1,-1))
image(t(mantaPct)[, nrow(mantaPct):1], xaxt='n')
plotPSD(manta, style='quantile', q=c(.01), 
        freqRange=c(10, 2e3))
```



## MANTA

Stand alone app exists for Mac/windows to process data. Supports easy 
batch processing on as many cpus available. Stand alone can support
different app imports (GPL detector, other detectors, etc.)

Fancier RavenX version also exists to better schedule jobs and apply
multiple algorithms. RavenX lets you run multiple detection/summary
algs. RavenX reqs matlab written algorithms, but once they are written
can easily incorporate new things. 

## PyPAM

Will do example notebook day 2. Computes stuff like manta, has
hydrophone calibration settings stored in objects (for SoundTrap
it will take serial number and pull from website)

## Future needs discussion

What is kurtosis lol

# Day 2

Case studies & notebooks later

## Megan acoustic scene analysis

DCASE group detection classification of acoustic scenes

Worried about data augmention (bird+insect = birdinsect) causing
overfitting, but idk if thats necessarily true? not sure how
theyre presenting their accuracy results, i would assume they 
have a real val set

IDK if relevant, Carly linked biodiversity + acoustics paper https://storage.googleapis.com/rfcx-wordpress-media/2023/09/f78fca73-harnessing-the-power-of-sound-and-ai-to-track-global-biodiversity-framework-gbf-targets.pdf

Talking a lot about how granular an acoustic scene cateogry needs to go, im
skeptical that species-level scenes are going to be realistic. Mo betta seems
a higher level (healthy reef, heavy vessel, etc.) and then that could
potentially inform a classification you might do at a lower level step.

Seems like could maybe be used to help rule out false positives? but also
if you do have a lone TP, that is likely not enough to influence a scene

lol `plotAcousticScene` is not related to this definition of acoustic scene

## Axiom data science people - soundcoop portal

sensors.ioos.us has enviro sensors
soundcoop.portal.axds.co is their demo for investigating datasets+buoy data
github.com/ioos/soundcoop

# TODO STUFF

- `checkSoundscapeInput` for a folder of files?
- Should probs download a year or month or something of Manta HMD data
for testing some things
- Add column name reqs (UTC, Latitude, Longitude) to tutorial doc for `matchGFS`
- Send Megan `matchEnvData` example for ERDDAP
- AIS summary stuff worry about vessel length for computing summary metrics
- Add ability to control dB scale for `plotTimeseries` color scaling (so different
datasets could have exact same color scale ranged from 80-120dB or whatever)
- Order of PAMscapesTutorial.rmd is all over the place
- Add multiple base urls to cycle through for `erddapToEdinfo` or whatever it is,
not just default upwell but will try others on initial fail
- HMD option for `createOctaveLevel`? to try from full PSD
- `matchGFS` probably needs to be deprecated and migrated to `PAMmisc::matchEnvData`
for consistency. Can just call it internall if `dataset='GFS'` or something like
that.
- Probably add a similar path for `dataset='HYCOM'` so that it is easier
- Easier pathway for different erddap server - can do something like baseurl::dataset?
- Add frequency limits for PSD reading stuff maybe
- https://erddap.sensors.ioos.us/erddap matches sensors.ioos.us
- example of `plotPSD(by=)` with their wind > 8 wind < 8 whatever
cutoffs
- Awkward path to get enviro directly on soundscape - need to add
lat/long columns, but then all my funs will get mad with extra columns. I probably
need to have a better column checker that can auto-drop extras instead of
just taking a dump. Hm, but then `toLong/toWide` will also take a dump? Carefully
^ maybe add a lat/long option to `matchEnvData` for people with stationary
things?
- Jupyter R notebook showing some of our pamscapes / env data stuff?
- Add sum and divide by bandwidth option to `createOctaveLevel`
- Bug Sam about GCP costs for hosting Viame video shizz

# PAM Archive Day

Expanding KBs work to others for pre-filling DB - how to extend this to
be useful for others? Have a master list of various fields, for others
need to point to potential source of those data. Currently for us all
in spreadsheets/dataframes. Potentially others are in a database. Could have
something like a passiveMapper that creates the source-field map for different
types, then you can save that and then just say go later. Could be shared
for any R users, not suuuuuuuper sure how it would work.

^^ Hm. Maybe start as a json file listing all fields, then format the
source:location for each field like `df:column` or `spreadsheet:column`
or `db:table:column`. source could be labeled like db1 db2 or whatever,
then separate file saying the exact file that goes for db1 etc. Could
also have something to list what rows of that you want to add, in addition
to checking for existing based on project ID. Hm tricky if multiple sources
bc different indices so not straight forward to ensure alignment. Would
need a source-source joining column. Marie brought up good point about
errors in spreadsheets, not sure what kind of error checking could be
embedded in this sort of thing. 

www.ncei.noaa.gov/products/passive-acoustic-data

Google bioacoustics Perch group - creating open source models
for ecologists to work with
github.com/google-research/perch

# Passive Packer Later Meeting Feb2024

Our approach is to fill most automatically, Kourtney started by filling
one in using PassivePacker, then we looked at the database to see what
columns our data went into. Then she mapped those database columns to
the columns in our various spreadsheets. Not all of our data is actually
stored in places, some just needs to be manual (e.g people, places,
funding). So we pre-fill what we can, then finish off in PP tool. Even
if it was all present, we think it is valuable to have someone look at it.

## Thoughts for tool

Sampling effort will be hard - probably needs its own tool.

Might need a row index option for inputs

Fully automating is a little scary because if your input formats change 
and you don't remember, you'll package and send it all

TALK TO MARIE ABOUT ADAPTING TETHYS MAPPER TOOL FOR THIS SO I DONT
HAVE TO DO ALL THE WORK

# Soundcoop2024! Day 1

Axiom presentation - how does their spectrogram load so fast for a full year
of data. Image pyramid IDK wtf that means. How are they compressing - median
or some such, or just downsampling?

Showing distribution of categories in a `plotPSD(by='')` plot is smart for
environmental data so you know if you have small sample size for some

Okay fine I'll add the code text to `runSoundscapeExplorer`

`plotLTSA` also needs a `by` column to create the multi-LTSA style plot thats 
in the slides. I guess that's pretty awkward and maybe breaks if time scales 
are different...e.x. if you try and do a jank environmental category or something

Question - is it appropriate to `createOctaveLevel` based on HMD data? bc of
the different frequency spacing

Default color scaling from 50 to 105 on the Soundcoop portal. Me too?

Coverage plot from Danelle's mybinder notebook example is useful. Is this
from the JSON metadata? Checking the actual date ranges? I wonder if these
should scale by % missing not % present - hard to see 99.5 vs 100% 

`ncdf4::ncatt_get(nc, varid=0, attname='geospatial_bounds')`
Hey it also has `time_coverage_start` and `_end`
And `platform` which has a title?

Data quality plotting - currently just marking NA on load, does this need
more options? Unfortunately going to require carrying a lot of crap around
and making sure that all the functions know how to continue carrying it.
e.g. `toWide` `toLong` are going to STB

decidecade option for `createOctaveLevel` ?

What is actually the "correct" time-binned/resampled summarisation? mean
is wrong, median is "okay", shouldn't linear-mean be best?

wtf is Dask for parallel/task organization (it does parallel kine stuff like
future package but more specific)

wtf is Zarr

Jonathan Joyce - my brain was getting too tired but something about getting
better access of WCOFS data. Will this work for the enviro we want? I dont
actually know what they did aybe i can find out later

## Day 2!

During Megan's talk, Carrie had a figure of sound level change since 2015, add
something like this. A plot like this won't fit in the soundscopeExplorer, but
we could just have a fixed figure with explanation "yo this doesnt work bc X,
but here's how you make it work". Orrrr I guess a data upload for comparison
datasets???. Hm.

Move a season function into PAMscapes for time of year labeling?

For the detection version of `soundscapeExplorer` - can have different
categories on the main page like "Detections ONly" "With Effort" whatever
based on different input needs. Probably add an effort adder to the data
page for that one. Data page will need a lot more options maybe? Binning
level, effort adder, call vs. species. Hm.

FOr `plotPSD` have something like if len(q) != 1 then we want to plot all
inputs as separate bands? Like pypam does 1,2,5,25,50, etc. all on one. 
Maybe good, maybe needs annoying reworking.

Email Jonathan Joyce about getting enviro data from them may have
easier stuff for our soundscape doohickeys

explorer should probably have a blurb on each plotting page about what
exactly you are looking at + how it gets there (eg if binning is happening
before plotting or w/e)

Add frequency limits to data panel (to filter)

QAQC - need to differentiate between soundtrap specific and general recorder use plots

Megan GCP checking JSONS to create gant chart. Check out `gsutil` and see how
works - some people having problems getting it working so try and see. We want this
in PAMscapes probs.


*M*odeling *U*nderwater *S*ounds to *U*nderstand *B*ehavior of *I*mportant Species

*D*eriving *A*coustic *K*nowledge from *I*ndepentent *N*etwork of  glid*E*rs

*H* *O* *W* *Z*iphius *I*ndividual *T*racklines *B*ehavioral *R*esponse p*A*ssing s*H*ips
